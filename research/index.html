<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.6.0 for Hugo"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload='this.media="all"'><meta name=author content="Kelley Kan HUANG"><meta name=description content="A highly-customizable Hugo academic resume theme powered by Wowchemy website builder."><link rel=alternate hreflang=en-us href=https://AI-Huang.github.io/research/><meta name=theme-color content="#1565c0"><link rel=stylesheet href=/css/vendor-bundle.min.c7b8d9abd591ba2253ea42747e3ac3f5.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css integrity="sha512-W0xM4mr6dEP9nREo7Z9z+9X70wytKvMGeDsj7ps2+xg5QPrEBXC8tAW1IFnzjR6eoJ90JmCnFzerQJTLzIEHjA==" crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=/css/wowchemy.3495fc6150afdd177f1d04fbba9f5e2c.css><link rel=stylesheet href=/css/libs/chroma/github-light.min.css title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=/css/libs/chroma/dracula.min.css title=hl-dark media=print onload='this.media="all"' disabled><link rel=alternate href=/research/index.xml type=application/rss+xml title=Academic><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_180x180_fill_lanczos_center_3.png><link rel=canonical href=https://AI-Huang.github.io/research/><meta property="twitter:card" content="summary"><meta property="twitter:site" content="@wowchemy"><meta property="twitter:creator" content="@wowchemy"><meta property="og:site_name" content="Academic"><meta property="og:url" content="https://AI-Huang.github.io/research/"><meta property="og:title" content="Research | Academic"><meta property="og:description" content="A highly-customizable Hugo academic resume theme powered by Wowchemy website builder."><meta property="og:image" content="https://AI-Huang.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png"><meta property="twitter:image" content="https://AI-Huang.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png"><meta property="og:locale" content="en-us"><meta property="og:updated_time" content="2022-12-01T17:28:00+08:00"><title>Research | Academic</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=bc8c75ec10f4acb491c3299f2f23af66><script src=/js/wowchemy-init.min.613040fe4f2c0f007b4dcb64404201cb.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class=page-header><header class=header--fixed><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Academic</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Academic</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class="nav-item dropdown"><a href=# class="nav-link dropdown-toggle" data-toggle=dropdown aria-haspopup=true><span>Home</span><span class=caret></span></a><div class=dropdown-menu><a class=dropdown-item href=/#skills><span>Skills</span></a>
<a class=dropdown-item href=/#experience><span>Experience</span></a>
<a class=dropdown-item href=/#entrepreneurship><span>Entrepreneurship</span></a>
<a class=dropdown-item href=/#courses><span>Courses</span></a>
<a class=dropdown-item href=/#awards><span>Awards</span></a></div></li><li class=nav-item><a class=nav-link href=/events><span>Events</span></a></li><li class=nav-item><a class=nav-link href=/posts><span>Posts</span></a></li><li class=nav-item><a class="nav-link active" href=/research><span>Research</span></a></li><li class=nav-item><a class=nav-link href=/publication><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/projects><span>Projects</span></a></li><li class=nav-item><a class=nav-link href=/teaching><span>Teaching</span></a></li><li class=nav-item><a class=nav-link href=/#contact><span>Contact</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span></a>
<a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span></a>
<a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></header></div><div class=page-body><div class="universal-wrapper pt-3"><h1>Research</h1></div><div class=universal-wrapper><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/research/replication_senet/>Replication of SENet</a></div><a href=/research/replication_senet/ class=summary-link><div class=article-style>This is a replication of the work SENet (J. Hu, et al., Squeeze-and-Excitation Networks). My codes:
Implement the SENet module; Apply the SENet module to the ResNet; Train the ResNet with SENet on CIFAR-10; Use the re-trained benchmark results of ResNet on CIFAR-10 for comparative evaluation.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span>Kan Huang</span></div><span class=article-date>Dec 1, 2022</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/1709.01507 target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/AI-Huang/SENet-tf target=_blank rel=noopener>Code</a></div></div><div class=ml-3></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/research/benchmark_resnet/>Benchmark of ResNet on CIFAR-10</a></div><a href=/research/benchmark_resnet/ class=summary-link><div class=article-style>This is a TensorFlow replication of experiments on CIFAR-10 mentioned in ResNet (K. He, et al., Deep Residual Learning for Image Recognition). My codes:
Adapts Keras&rsquo;s example codes of ResNet for CIFAR-10 (note that this is a simpler version specially designed for CIFAR-10); Apply the SENet module to the ResNet; Re-train the ResNet w/o SENet on CIFAR-10 for benchmark evaluation.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span>Kan Huang</span></div><span class=article-date>Nov 29, 2022</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/1512.03385 target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/AI-Huang/CV_Playground target=_blank rel=noopener>Code</a></div></div><div class=ml-3></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/research/greeneyes/>GreenEyes: An Air Quality Evaluating Model based on WaveNet</a></div><a href=/research/greeneyes/ class=summary-link><div class=article-style>Accepted by AMLTS 2022.
Presentation available at AMLTS 2022 Workshop.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><span class=article-date>Sep 18, 2022</span></div></div></div><div class=ml-3></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/research/rmnist_n/>RMNIST/N: Train MNIST dataset with only TEN samples</a></div><a href=/research/rmnist_n/ class=summary-link><div class=article-style>RMNIST/N is a dataset that reduces MNIST with N examples for each digit class. In this way, RMNIST/1 has 1 training example for each digit, for a total of only 10 training examples.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><span class=article-date>Aug 9, 2022</span>
<span class=middot-divider></span>
<span class=article-categories><i class="fas fa-folder mr-1"></i><a href=/category/deep-learning/>Deep Learning</a>, <a href=/category/data-augmentation/>Data Augmentation</a></span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/AI-Huang/CV_Playground target=_blank rel=noopener>Code</a></div></div><div class=ml-3></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/research/flow_model/>Image Compression with Flow Models</a></div><a href=/research/flow_model/ class=summary-link><div class=article-style>Found new approaches of using flow models to do compression tasks for image‐like data. Wrote processing and feature extracting functions for 80K+ target data. Tested VQ‐VAE and basic Real NVP model to build unsupervising learning baselines; Based on open source codes, wrote hundreds lines of extra codes to restore Real NVP Compression model introduced by the SOTA papers.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><span class=article-date>May 18, 2021</span></div></div></div><div class=ml-3></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/research/addernet_tensorflow/>A TensorFlow Implementation of AdderNet</a></div><a href=/research/addernet_tensorflow/ class=summary-link><div class=article-style>This is a A TensorFlow Implementation of AdderNet. The original paper, AdderNet (H. Chen, et al., AdderNet: Do We Really Need Multiplications in Deep Learning?), is implemented with PyTorch. Here we provide a TensorFlow alternative for training and evaluating the Adder layer operator and related network backbones.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span>Kan Huang</span></div><span class=article-date>Jan 29, 2021</span>
<span class=middot-divider></span>
<span class=article-categories><i class="fas fa-folder mr-1"></i><a href=/category/codes/>Codes</a>, <a href=/category/networks/>Networks</a></span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/1912.13200 target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/AI-Huang/AdderNet-tf target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://drive.google.com/file/d/1KPZlWL3mP8Q-aH1mbpf42vl9M-3t106j/view?usp=share_link" target=_blank rel=noopener>Slides</a></div></div><div class=ml-3></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/research/addernet_presentation/>AdderNet Presentation</a></div><a href=/research/addernet_presentation/ class=summary-link><div class=article-style>This is a paper digest sharing presentation in the reading group. The featured paper is AdderNet (H. Chen, et al., AdderNet: Do We Really Need Multiplications in Deep Learning?).
Presentation slides is available (click the &ldquo;Slides&rdquo; button).</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span>Kan Huang</span></div><span class=article-date>Jan 29, 2021</span>
<span class=middot-divider></span>
<span class=article-categories><i class="fas fa-folder mr-1"></i><a href=/category/reading-group/>Reading Group</a></span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/1912.13200 target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/huawei-noah/AdderNet target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://drive.google.com/file/d/1KPZlWL3mP8Q-aH1mbpf42vl9M-3t106j/view?usp=share_link" target=_blank rel=noopener>Slides</a></div></div><div class=ml-3></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/research/semi_conductor/>Semi-conductor Image Classification</a></div><a href=/research/semi_conductor/ class=summary-link><div class=article-style>Helped Prof. YAO Yuan and the Nexperia company with the Nexperia semi‐conductor classification problem; Distinguished broken chips from normal chips by using deep learning and image classification methods; Compared the difference of perform between different models, e.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><span class=article-date>Jan 30, 2020</span></div></div></div><div class=ml-3></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/research/seq2seq_chatbot/>Seq2Seq Chatbot</a></div><a href=/research/seq2seq_chatbot/ class=summary-link><div class=article-style>This program:
Builds a Seq2Seq model and learn on the text dataset; Uses beam search algorithm to generate output; Supplys a dialogue robot backend for the Chatbot. Other parts of the Chatbot.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><span class=article-date>May 30, 2019</span></div></div><div class=btn-links></div></div><div class=ml-3></div></div></div></div><div class=page-footer><div class=container><footer class=site-footer><p class="powered-by copyright-license-text">© 2022 Me. This work is licensed under <a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank>CC BY NC ND 4.0</a></p><p class="powered-by footer-license-icons"><a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank aria-label="Creative Commons"><i class="fab fa-creative-commons fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-by fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nc fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nd fa-2x" aria-hidden=true></i></a></p><p class=powered-by>Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> — the free, <a href=https://github.com/wowchemy/wowchemy-hugo-themes target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></div><script src=/js/vendor-bundle.min.d26509351aa0ff874abbee824e982e9b.js></script>
<script id=search-hit-fuse-template type=text/x-template>
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script><script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script>
<script id=page-data type=application/json>{"use_headroom":true}</script><script src=/js/wowchemy-headroom.c251366b4128fd5e6b046d4c97a62a51.js type=module></script>
<script src=/en/js/wowchemy.min.54dd6e4d8f2e4b1d098381b57f18dd83.js></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=/js/wowchemy-publication.68f8d7090562ca65fc6d3cb3f8f2d2cb.js type=module></script></body></html>